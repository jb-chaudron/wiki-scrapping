# wiki-scrapping
Data Extraction and Preprocessing of Wikipedia Articles

## The "Main" Directory
Contains the usefull bit of code,
- The extraction of the featured article in "Extraction" directory
- The Preprocessing of these articles and there transformation into Spacy's objects
- The Extraction and Processing of the Categories of the articles into a graphs, plus an embedding part, in order to make the manipulation of categories easier.

## The "Data" Directory
Contains some data, though it is not an exhaustive list of the data we worked with

## The "Non-Relevant" Directory
Contains some code that was considered/used at some point, it might still contains interessting functions and stuff, but these aren't ready to use
